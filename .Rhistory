dpfa.out$ZZip_est[1:3,1:10]
dpfa.out$ZZip_est[1:3,1:30]
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=2,
init_con_H=1)
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=2,
init_con_H=1)
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=2,
init_con_H=1)
NA > .3
(NA > .3)*1
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=2,
init_con_H=1)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=20,
init_con_H=1)
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=20,
init_con_H=1)
warnings()
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=20,
init_con_H=1)
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=20,
init_con_H=1)
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=20,
init_con_H=1)
library(dpfa)
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=20,
init_con_H=1)
dpfa.out$psi_est
dpfa.out$phi_est
summary(t(dpfa.out$ZZip_est))
unique(t(dpfa.out$ZZip_est))
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=20,
init_con_H=1)
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=2000,
init_con_H=1)
?mode
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=20,
init_con_H=1)
dpfa.out$ZZip_est
dpfa.out$ZZip_est[1:3,1:3]
summary(t(dpfa.out$ZZip_est))
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=2000,
init_con_H=1)
summary(t(dpfa.out$ZZip_est))
summary(t(dpfa.out$H_tru))
str(ret)
summary(t(ret[[4]]))
h_tru ret[[4]]
h_tru = ret[[4]]
zzip dpfa.out$ZZip_est
zzip = dpfa.out$ZZip_est
zzip == h_tru
mean(zzip == h_tru)
dpfa.out$W_est
summary(t(dpfa.out$W_est))
w_tru = ret[[5]]
summary(t(dpfa.out$w_tru))
w_tru = ret[[5]]
str(w_tru)
summary(t(w_tru))
summary(t(dpfa.out$W_est))
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
rgamma(1,3,0.5)
summary(t(dpfa.out$W_est))
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=2,
init_con_H=1)
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=2,
init_con_H=1)
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=2,
init_con_H=1)
K=3
bias_0 = rep(2,K)
BPL<-function(lambda,K){
prob = 1-exp(-lambda)
out = rbern(rep(1,K),prob)
return(matrix(out, nrow = K))
}
BPL(bias_0,K)
BPL(bias_0,K)
BPL(bias_0,K)
BPL(bias_0,K)
BPL(bias_0,K)
BPL(bias_0,K)
BPL(bias_0,K)
BPL(bias_0,K)
BPL(bias_0,K)
BPL(bias_0,K)
BPL(bias_0,K)
BPL(bias_0,K)
BPL(bias_0,K)
lambda=2
1-exp(-lambda)
1-exp(-lambda)
1-exp(-lambda)
1-exp(-lambda)
1-exp(-lambda)
1-exp(-lambda)
1-exp(-lambda)
1-exp(-lambda)
ret = true_data_Cond3(K=3, numSample=30, M=15, numTime=100,bias=0)
ret = true_data_Cond3(K=3, numSample=30, M=15, numTime=100,bias_0=0)
source("true_data_Cond3.R")
ret = true_data_Cond3(K=3, numSample=30, M=15, numTime=100,bias_0=0)
ret = true_data_Cond3(K=3, numSample=30, M=15, numTime=100,bias=0)
setwd("/Volumes/GoogleDrive/Shared drives/SLAM Lab/dpfa_sim")
source("true_data_Cond3.R")
ret = true_data_Cond3(K=3, numSample=30, M=15, numTime=100,bias=0)
h_tru = ret[[4]]
summary(t(h_tru))
bias_0 = rep(bias,K)
bias=0
bias_0 = rep(bias,K)
BPL(bias_0,K)
BPL(bias_0,K)
BPL(bias_0,K)
BPL(bias_0,K)
BPL(bias_0,K)
lambda=0
1-exp(-lambda)
1-exp(-lambda)
1-exp(-lambda)
1-exp(-lambda)
lambda=.2
1-exp(-lambda)
1-exp(-lambda)
1-exp(-lambda)
1-exp(-lambda)
1-exp(-lambda)
1-exp(-lambda)
1-exp(-lambda)
ret = true_data_Cond3(K=3, numSample=30, M=15, numTime=100,bias=0.5)
h_tru = ret[[4]]
summary(t(h_tru))
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=2,
init_con_H=1)
library(dpfa)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=2,
init_con_H=1)
# vector memory limit at 10000 iters
# need 5000 iters
dpfa.out = dpfa(data,
K=3,
N=30,
M=15,
alpha_phi=5,
numTime=100,
niter=2000,
init_con_H=1)
summary(t(dpfa.out$ZZip_est))
dpfa.out$psi_est
dpfa.out$phi_est
library(tidyverse)
library(keras); library(tidyr); library(dplyr); library(purrr);library(tokenizers)
library(ggplot2);library(pROC); library(stringr);library(tidytext)
library(topicmodels);library(stringi);  library(caret)
setwd("/Volumes/GoogleDrive/Shared drives/ASSIST - SLAM Ongoing Research/rEMA/")
rema_text <- read_sav("Remote EMA_EOD Text.sav")
unique(rema_text$ID)
rema_text$MentalState
rema_text$Hopeless
rema_text$Stressors
rema_text$Connected
comb_text = unite(data.frame(rema_text$MentalState,rema_text$Hopeless,rema_text$Stressors,rema_text$Connected),"comb",sep=" ")
# time
rema_text$RecordedDate
# amount of time it took to fill out
rema_text$Duration__in_seconds_
# just start with Hopeless
comb = comb_text$comb
comb = str_replace_all(comb, "\n", "")
comb = str_replace_all(comb, "\\n", "")
comb = str_replace_all(comb, "NA", "")
comb = gsub("\\x", "", comb)# ditto
comb2 = as.character(unlist(comb))
comb3 = tibble(document=1:length(comb2), text=comb2)
comb4 = mutate(comb3, text = gsub(x = text, pattern = "[0-9]+|[[:punct:]]|\\(.*\\)", replacement = ""))
comb5 = cbind(id=rema_text$ID,comb4[,-1])
library(textmineR)
dtm <- CreateDtm(comb5$text)
dtm2 <- dtm[,colSums(dtm) > 40]
dtm.mat = as.matrix(dtm2)
setwd("/Volumes/GoogleDrive/Shared drives/ASSIST - SLAM Ongoing Research/rEMA/")
rema_text <- read_sav("Remote EMA_EOD Text.sav")
library(haven)
setwd("/Volumes/GoogleDrive/Shared drives/ASSIST - SLAM Ongoing Research/rEMA/")
rema_text <- read_sav("Remote EMA_EOD Text.sav")
unique(rema_text$ID)
rema_text$MentalState
rema_text$Hopeless
rema_text$Stressors
rema_text$Connected
comb_text = unite(data.frame(rema_text$MentalState,rema_text$Hopeless,rema_text$Stressors,rema_text$Connected),"comb",sep=" ")
# time
rema_text$RecordedDate
# amount of time it took to fill out
rema_text$Duration__in_seconds_
# just start with Hopeless
comb = comb_text$comb
comb = str_replace_all(comb, "\n", "")
comb = str_replace_all(comb, "\\n", "")
comb = str_replace_all(comb, "NA", "")
comb = gsub("\\x", "", comb)# ditto
comb2 = as.character(unlist(comb))
comb3 = tibble(document=1:length(comb2), text=comb2)
comb4 = mutate(comb3, text = gsub(x = text, pattern = "[0-9]+|[[:punct:]]|\\(.*\\)", replacement = ""))
comb5 = cbind(id=rema_text$ID,comb4[,-1])
library(textmineR)
dtm <- CreateDtm(comb5$text)
dtm2 <- dtm[,colSums(dtm) > 40]
dtm.mat = as.matrix(dtm2)
str(dtm.mat)
rema_text$RecordedDate
str(rema_text)
as.POSIXct(rema_text$RecordedDate)
as.numeric(as.POSIXct(rema_text$RecordedDate))
time.num = as.numeric(as.POSIXct(rema_text$RecordedDate))
time.num = as.numeric(as.POSIXct(rema_text$RecordedDate))
time.num = time.num/60
time.num = time.num/60
time.num
rema_text$time = time.num
rema_text$time_0 = NA
tabb = table(rema_text$ID)
tabb
id = names(which(table(rema_text$ID) < 20))
rema_text2 = rema_text[!rema_text$ID %in% id,]
rema_text2$time_0 = NA
tabb = table(rema_text2$ID)
tabb
for(i in 1:length(tabb)){
nam = names(tabb[i])
rema_text2[rema_text2$ID == nam,"time_0"] = rema_text2[rema_text2$ID == nam,"time"] - min(rema_text2[rema_text2$ID == nam,"time"])
}
rema_text2$time_0
comb_text = unite(data.frame(rema_text2$MentalState,rema_text2$Hopeless,rema_text2$Stressors,rema_text2$Connected),"comb",sep=" ")
rema_text$Duration__in_seconds_
comb = comb_text$comb
comb = str_replace_all(comb, "\n", "")
comb = str_replace_all(comb, "\\n", "")
comb = str_replace_all(comb, "NA", "")
comb = gsub("\\x", "", comb)# ditto
comb2 = as.character(unlist(comb))
comb3 = tibble(document=1:length(comb2), text=comb2)
comb4 = mutate(comb3, text = gsub(x = text, pattern = "[0-9]+|[[:punct:]]|\\(.*\\)", replacement = ""))
comb5 = cbind(id=rema_text$ID,comb4[,-1])
library(textmineR)
dtm <- CreateDtm(comb5$text)
dtm2 <- dtm[,colSums(dtm) > 40]
dtm.mat = as.matrix(dtm2)
text_dat = data.frame(ID=rema_text2$ID,time_0=rema_text2$time_0,dtm.mat)
comb = comb_text$comb
comb = str_replace_all(comb, "\n", "")
comb = str_replace_all(comb, "\\n", "")
comb = str_replace_all(comb, "NA", "")
comb = gsub("\\x", "", comb)# ditto
comb2 = as.character(unlist(comb))
comb3 = tibble(document=1:length(comb2), text=comb2)
comb4 = mutate(comb3, text = gsub(x = text, pattern = "[0-9]+|[[:punct:]]|\\(.*\\)", replacement = ""))
comb5 = cbind(id=rema_text2$ID,comb4[,-1])
comb5 = cbind(id=rema_text2$ID,time_0=rema_text2$time_0,comb4[,-1])
library(textmineR)
dtm <- CreateDtm(comb5$text)
dtm2 <- dtm[,colSums(dtm) > 40]
?CreateDtm
dtm.mat = as.matrix(dtm2)
str(dtm.mat)
text_dat = data.frame(ID=comb5$ID,time_0=comb5$time_0,dtm.mat)
text_dat = data.frame(ID=comb5$id,time_0=comb5$time_0,dtm.mat)
str(text_dat)
colnames(dtm.mat)
ll = matrix(paste("l",rep(1:ncol(dtm.mat)),sep=""),ncol(dtm.mat),1)
mod1 <- ctModel(type="stanct",id="id",time="time_0",
n.latent=1,n.manifest=ncol(dtm.mat),
manifestNames=colnames(dtm.mat),
latentNames=c("f1"),
LAMBDA=ll)
library(ctsem)
mod1 <- ctModel(type="stanct",id="id",time="time_0",
n.latent=1,n.manifest=ncol(dtm.mat),
manifestNames=colnames(dtm.mat),
latentNames=c("f1"),
LAMBDA=ll)
fit1 <- ctStanFit(datalong=text_dat,ctstanmodel=mod1,iter=1000,chains=4,cores=4,
stationary=F,optimize=T)
summary(fit1)
dtm2 <- dtm[,colSums(dtm) > 100]
str(dtm2)
dtm.mat = as.matrix(dtm2)
text_dat = data.frame(ID=comb5$id,time_0=comb5$time_0,dtm.mat)
colnames(dtm.mat)
library(ctsem)
ll = matrix(paste("l",rep(1:ncol(dtm.mat)),sep=""),ncol(dtm.mat),1)
mod1 <- ctModel(type="stanct",id="id",time="time_0",
n.latent=1,n.manifest=ncol(dtm.mat),
manifestNames=colnames(dtm.mat),
latentNames=c("f1"),
LAMBDA=ll)
fit1 <- ctStanFit(datalong=text_dat,ctstanmodel=mod1,iter=1000,chains=4,cores=4,
stationary=F,optimize=T)
library(textmineR)
dtm <- CreateDtm(comb5$text)
dtm2 <- dtm[,colSums(dtm) > 100]
dtm.mat = as.matrix(dtm2)
text_dat = data.frame(ID=comb5$id,time_0=comb5$time_0,dtm.mat)
colnames(dtm.mat)
library(ctsem)
ll = matrix(paste("l",rep(1:ncol(dtm.mat)),sep=""),ncol(dtm.mat),1)
colnames(text_dat)
mod1 <- ctModel(type="stanct",id="ID",time="time_0",
n.latent=1,n.manifest=ncol(dtm.mat),
manifestNames=colnames(dtm.mat),
latentNames=c("f1"),
LAMBDA=ll)
ll = matrix(paste("l",rep(1:ncol(dtm.mat)),sep=""),ncol(dtm.mat),1)
mod1 <- ctModel(type="stanct",id="ID",time="time_0",
n.latent=1,n.manifest=ncol(dtm.mat),
manifestNames=colnames(dtm.mat),
latentNames=c("f1"),
LAMBDA=ll)
fit1 <- ctStanFit(datalong=text_dat,ctstanmodel=mod1,iter=1000,chains=4,cores=4,
stationary=F,optimize=T)
